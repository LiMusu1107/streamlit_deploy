import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
import os
import sys
import tempfile
from io import BytesIO
import warnings
import matplotlib.pyplot as plt
from lifelines import CoxPHFitter

warnings.filterwarnings('ignore')

# æ·»åŠ mogonetæ¨¡å—åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'mogonet')))

# å¯¼å…¥mogonetæ¨¡å—
try:
    from mogonet.models_FNN import init_model_dict
    from mogonet.train_test_FNN import test_epoch
    from mogonet.utils import load_model_dict_cpu, one_hot_tensor, cal_sample_weight
except ImportError:
    st.error("Error: Could not import mogonet modules. Please ensure the mogonet folder is in the correct location.")
    st.stop()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="LGG Comprehensive Prediction System",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åº”ç”¨æ ‡é¢˜
st.title("ğŸ¥ LGG Comprehensive Prediction System")

# åœ¨ä¾§è¾¹æ æ·»åŠ åº”ç”¨è¯´æ˜
st.sidebar.header("ğŸ“Š About")
st.sidebar.info("""
This application provides two complementary prediction tools for LGG (Low-Grade Glioma) patients:

1. **Survival Prediction**: Predicts survival probability based on clinical parameters
2. **Risk Group Prediction**: Predicts risk group (High/Low) based on multi-omics data

Use the Risk Group Prediction tool if you're unsure of the patient's risk group.
""")

# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šç”Ÿå­˜é¢„æµ‹å‚æ•°
# ============================================================================
st.sidebar.header("ğŸ”§ Survival Prediction Parameters")

# 1. Age slider (20-90)
age = st.sidebar.slider(
    "Age (years)",
    min_value=20,
    max_value=90,
    value=50,
    step=1,
    help="Select patient age between 20 and 90 years"
)

# 2. Grade selection
grade_options = ['G2', 'G3']
grade = st.sidebar.selectbox(
    "Grade",
    options=grade_options,
    index=1,  # Default to G3
    help="Select tumor grade (G2 or G3)"
)

# 3. Risk group selection
risk_options = {
    "High": 1,
    "Low": 0
}
risk_label = st.sidebar.selectbox(
    "Risk Group",
    options=list(risk_options.keys()),
    index=0,  # Default to High
    help="Select risk group (High = 1, Low = 0). Use the Risk Group Prediction tool below if unsure."
)
risk_value = risk_options[risk_label]

# æ·»åŠ ç”Ÿå­˜é¢„æµ‹è®¡ç®—æŒ‰é’®
survival_calc_button = st.sidebar.button(
    "ğŸš€ Calculate Survival Prediction",
    type="primary",
    use_container_width=True
)

# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šé£é™©ç»„åˆ«é¢„æµ‹å‚æ•°
# ============================================================================
st.sidebar.markdown("---")
st.sidebar.header("ğŸ§¬ Risk Group Prediction")

st.sidebar.markdown("""
Use this tool if you're unsure of the patient's risk group.
Upload multi-omics data to predict whether the patient is High or Low risk.
""")

# åœ¨ä¾§è¾¹æ æ·»åŠ æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
st.sidebar.subheader("ğŸ“¤ Upload Omic Data")
st.sidebar.markdown("Please upload CSV files for each omic type (50 features each):")

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
uploaded_files = {}

col1, col2, col3 = st.sidebar.columns(3)

with col1:
    uploaded_files["mRNA"] = st.file_uploader(
        "mRNA Data", 
        type=["csv"],
        help="Upload mRNA expression data (50 features)",
        key="mrna_uploader"
    )

with col2:
    uploaded_files["miRNA"] = st.file_uploader(
        "miRNA Data", 
        type=["csv"],
        help="Upload miRNA expression data (50 features)",
        key="mirna_uploader"
    )

with col3:
    uploaded_files["methylation"] = st.file_uploader(
        "Methylation Data", 
        type=["csv"],
        help="Upload DNA methylation data (50 features)",
        key="meth_uploader"
    )

# åœ¨ä¾§è¾¹æ æ·»åŠ é¢„æµ‹æ–¹å¼é€‰æ‹©
st.sidebar.subheader("ğŸ¯ Prediction Mode")
omic_type = st.sidebar.selectbox(
    "Select Prediction Mode",
    options=["multiomics", "mRNA", "miRNA", "methylation"],
    index=0,
    help="Select the prediction mode"
)

# æ˜¾ç¤ºå½“å‰é¢„æµ‹æ¨¡å¼çš„è¦æ±‚
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ” Mode Requirements")

if omic_type == "multiomics":
    st.sidebar.info("**Multiomics Mode**: Requires all three omic data files")
elif omic_type == "mRNA":
    st.sidebar.info("**mRNA Mode**: Requires only mRNA data file")
elif omic_type == "miRNA":
    st.sidebar.info("**miRNA Mode**: Requires only miRNA data file")
elif omic_type == "methylation":
    st.sidebar.info("**Methylation Mode**: Requires only methylation data file")

# æ·»åŠ é£é™©ç»„åˆ«é¢„æµ‹æŒ‰é’®
risk_calc_button = st.sidebar.button(
    "ğŸ§¬ Predict Risk Group",
    type="secondary",
    use_container_width=True
)

# åœ¨ä¾§è¾¹æ æ·»åŠ ä¸‹è½½ç¤ºä¾‹æ•°æ®çš„é“¾æ¥
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“ Example Data")
st.sidebar.markdown("""
Download example data files for testing:
- [mRNA Example](https://github.com/LiMusu1107/streamlit_deploy/raw/main/data/example_mrna.csv)
- [miRNA Example](https://github.com/LiMusu1107/streamlit_deploy/raw/main/data/example_mirna.csv)
- [Methylation Example](https://github.com/LiMusu1107/streamlit_deploy/raw/main/data/example_meth.csv)
""")

# ============================================================================
# æ¨¡å‹æ–‡ä»¶å¤¹æ˜ å°„
# ============================================================================
MODEL_MAP = {
    "multiomics": "model_trained/model-early-FNN-multiomics",
    "mRNA": "model_trained/model-early-FNN-mRNA_array",
    "miRNA": "model_trained/model-early-FNN-miRNA",
    "methylation": "model_trained/model-early-FNN-methy"
}

# é¢„æœŸç‰¹å¾ç»´åº¦
EXPECTED_DIMS = {
    "multiomics": 150,  # 3 * 50 features
    "mRNA": 50,
    "miRNA": 50,
    "methylation": 50
}

# ============================================================================
# é£é™©ç»„åˆ«é¢„æµ‹ç›¸å…³å‡½æ•°
# ============================================================================
@st.cache_data
def load_training_data():
    try:
        # åŠ è½½è®­ç»ƒç´¢å¼•
        train_idx = pd.read_csv("data/train_index.csv")
        train_idx = train_idx.values.flatten() - 1
        
        # åŠ è½½æ ‡ç­¾
        df_label = pd.read_csv("data/tcga_label2.csv")
        df_label = df_label.rename(columns={df_label.columns[1]: 'label'})
        label = df_label['label'].values - 1
        
        return train_idx, label
    except Exception as e:
        st.error(f"Error loading training data: {str(e)}")
        return None, None

# åˆå§‹åŒ–æ¨¡å‹
def init_and_load_model(model_folder, dim_list):
    try:
        # æ¨¡å‹ç»“æ„å‚æ•°
        view_list = [1]
        num_view = len(view_list)
        num_class = 2
        dim_hvcdn = 100
        dim_he_list = [300, 200, 100]
        dropout_rate = 0.5
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = init_model_dict(
            num_view, num_class, dim_list, dim_he_list, dim_hvcdn, dropout_rate
        )
        
        # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        return load_model_dict_cpu(model_folder, model)
    except Exception as e:
        st.error(f"Error initializing or loading model: {str(e)}")
        return None

# å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
def process_uploaded_file(uploaded_file, expected_dim=50):
    try:
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å¤„ç†ä¸Šä¼ 
        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        # è¯»å–CSVæ–‡ä»¶
        df = pd.read_csv(tmp_file_path)
        
        # æ£€æŸ¥ç»´åº¦
        if df.shape[1] != expected_dim:
            st.error(f"Invalid dimension. Expected {expected_dim} features, got {df.shape[1]}.")
            return None, f"Expected {expected_dim} features, got {df.shape[1]}"
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_file_path)
        
        return df.to_numpy(), None
    except Exception as e:
        st.error(f"Error processing uploaded file: {str(e)}")
        return None, str(e)

# æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶éƒ½å·²ä¸Šä¼ 
def check_required_files(omic_type, uploaded_files):
    required_files = []
    
    if omic_type == "multiomics":
        required_files = ["mRNA", "miRNA", "methylation"]
    elif omic_type == "mRNA":
        required_files = ["mRNA"]
    elif omic_type == "miRNA":
        required_files = ["miRNA"]
    elif omic_type == "methylation":
        required_files = ["methylation"]
    
    missing_files = []
    for file_type in required_files:
        if file_type not in uploaded_files or uploaded_files[file_type] is None:
            missing_files.append(file_type)
    
    return missing_files

# ============================================================================
# ç”Ÿå­˜é¢„æµ‹ç›¸å…³å‡½æ•°
# ============================================================================
def perform_survival_prediction(age, grade, risk_value, risk_label):
    with st.spinner("ğŸ”¬ Loading data and training model..."):
        # 1. è¯»å–æ•°æ®
        data_tcga = pd.read_csv("survdata_tcga_lgg.csv")
        
        # 2. è½¬æ¢åˆ†ç±»å˜é‡
        categorical_cols = ['label2', 'grade', 'histological_type', 'IDH']
        for col in categorical_cols:
            if col in data_tcga.columns:
                data_tcga[col] = data_tcga[col].astype('category')
        
        # 3. å‡†å¤‡ç”¨äºCoxæ¨¡å‹çš„æ•°æ®
        data_for_cox = data_tcga[['os', 'censor', 'age', 'grade', 'label2']].copy()
        data_for_cox = data_for_cox.dropna()
        
        # 4. æ‹ŸåˆCoxæ¯”ä¾‹é£é™©æ¨¡å‹
        cph = CoxPHFitter()
        cph.fit(data_for_cox, duration_col='os', event_col='censor', 
                formula='age + grade + label2')
        
        # 5. æ ¹æ®ç”¨æˆ·è¾“å…¥åˆ›å»ºæ–°æ‚£è€…æ•°æ®
        new_patient = pd.DataFrame({
            'age': [age],
            'grade': pd.Categorical([grade]),
            'label2': pd.Categorical([risk_value])
        })
        
        # 6. é¢„æµ‹ç”Ÿå­˜å‡½æ•°
        survival_function = cph.predict_survival_function(new_patient)
        
        # è½¬æ¢ä¸ºDataFrame
        survival_df = pd.DataFrame({
            'time': survival_function.index,
            'surv': survival_function.iloc[:, 0]
        })
        
        # 7. è®¡ç®—ç‰¹å®šæ—¶é—´ç‚¹çš„ç”Ÿå­˜ç‡
        time_points = [12, 36, 60, 84, 108, 120]  # 1,3,5,7,9,10å¹´
        time_labels = ['1 year', '3 years', '5 years', '7 years', '9 years', '10 years']
        
        results = []
        for t, label in zip(time_points, time_labels):
            idx = (survival_df['time'] - t).abs().idxmin()
            if idx < len(survival_df):
                surv_prob = survival_df.loc[idx, 'surv']
                se = surv_prob * (1 - surv_prob) / np.sqrt(len(data_for_cox))
                ci_lower = max(0, surv_prob - 1.96 * se)
                ci_upper = min(1, surv_prob + 1.96 * se)
                
                results.append({
                    'Time': label,
                    'Survival Rate (%)': f"{surv_prob * 100:.2f}%",
                    '95% CI': f"[{ci_lower * 100:.2f}%, {ci_upper * 100:.2f}%]"
                })
        
        survival_results = pd.DataFrame(results)
        
        # 8. åˆ›å»ºå›¾è¡¨
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), 
                                       gridspec_kw={'height_ratios': [3, 1]})
        
        # ç»˜åˆ¶ç”Ÿå­˜æ›²çº¿
        ax1.step(survival_df['time'], survival_df['surv'], 
                 linewidth=2, color='#25558F', where='post')
        ax1.fill_between(survival_df['time'], 
                          survival_df['surv'] * 0.9,
                          survival_df['surv'] * 1.1,
                          alpha=0.2, color='#25558F')
        
        # æ ‡è®°ç‰¹å®šçš„æ—¶é—´ç‚¹
        for t, label in zip(time_points, time_labels):
            idx = (survival_df['time'] - t).abs().idxmin()
            if idx < len(survival_df):
                ax1.scatter(t, survival_df.loc[idx, 'surv'], 
                           color='red', s=50, zorder=5)
                ax1.text(t, survival_df.loc[idx, 'surv'] + 0.05, 
                        f'{label}\n{survival_df.loc[idx, "surv"]:.1%}',
                        ha='center', fontsize=10)
        
        ax1.set_xlabel('Survival Time (months)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Survival Probability', fontsize=12, fontweight='bold')
        ax1.set_title(f'Predicted Survival Curve for {age}-year-old patient\n'
                     f'Grade: {grade}, Risk Group: {risk_label}', 
                     fontsize=14, fontweight='bold', color='#25558F')
        ax1.set_xlim([0, 125])
        ax1.set_ylim([0, 1.05])
        ax1.set_xticks(range(0, 121, 12))
        ax1.set_yticks(np.arange(0, 1.1, 0.2))
        ax1.tick_params(axis='both', labelsize=10)
        
        ax1.grid(True, alpha=0.3)
        ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
        
        # æ·»åŠ è¡¨æ ¼
        ax2.axis('tight')
        ax2.axis('off')
        
        table = ax2.table(cellText=survival_results.values,
                         colLabels=survival_results.columns,
                         cellLoc='center',
                         loc='center',
                         colColours=['#f0f0f0']*len(survival_results.columns))
        
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 1.8)
        
        plt.tight_layout()
        
        return fig, survival_df, survival_results, cph, data_for_cox

# ============================================================================
# ä¸»åº”ç”¨é€»è¾‘
# ============================================================================
# åˆå§‹åŒ–session state
if 'risk_prediction_result' not in st.session_state:
    st.session_state.risk_prediction_result = None
if 'last_risk_value' not in st.session_state:
    st.session_state.last_risk_value = None
if 'last_risk_label' not in st.session_state:
    st.session_state.last_risk_label = None

# ä¸»å†…å®¹åŒºåŸŸ
# å¦‚æœæ²¡æœ‰ä»»ä½•è®¡ç®—ï¼Œæ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
if not survival_calc_button and not risk_calc_button:
    st.markdown("""
    ## Welcome to LGG Comprehensive Prediction System
    
    This application provides two complementary prediction tools for LGG (Low-Grade Glioma) patients:
    
    ### 1. Survival Prediction
    Predicts survival probability based on clinical parameters:
    - **Age**: Patient age in years
    - **Grade**: Tumor grade (G2/G3)
    - **Risk Group**: High (1) or Low (0) risk
    
    ### 2. Risk Group Prediction
    Predicts risk group (High/Low) based on multi-omics data when you're unsure of the risk group.
    - Supports multiomics, mRNA, miRNA, and methylation data
    - Each omic data file should have exactly 50 features
    
    ### How to use:
    1. **Set survival prediction parameters** in the first section of the sidebar
    2. **Optionally, use risk group prediction** in the second section if unsure of risk group
    3. **Click the respective calculation buttons**
    4. **View results** in the main area
    
    â¬…ï¸ **Please set parameters in the sidebar and click the calculation buttons.**
    """)
    
    # æ˜¾ç¤ºç¤ºä¾‹å›¾ç‰‡å ä½ç¬¦
    st.info("ğŸ‘ˆ Set parameters in the sidebar and click calculation buttons to see results.")

# å¤„ç†é£é™©ç»„åˆ«é¢„æµ‹
if risk_calc_button:
    st.subheader("ğŸ§¬ Risk Group Prediction Results")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶éƒ½å·²ä¸Šä¼ 
    missing_files = check_required_files(omic_type, uploaded_files)
    
    if missing_files:
        st.error(f"Missing required files for {omic_type} prediction: {', '.join(missing_files)}")
        st.info("Please upload the missing files in the sidebar.")
    else:
        # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
        with st.spinner("Processing uploaded data..."):
            data_arrays = {}
            errors = []
            
            # å¤„ç†æ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶
            for file_type, uploaded_file in uploaded_files.items():
                if uploaded_file is not None:
                    data_array, error = process_uploaded_file(uploaded_file, expected_dim=50)
                    if error:
                        errors.append(f"{file_type}: {error}")
                    elif data_array is not None:
                        data_arrays[file_type] = data_array
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤„ç†é”™è¯¯
            if errors:
                st.error("Errors processing uploaded files:")
                for error in errors:
                    st.error(f"- {error}")
            else:
                # æ ¹æ®é¢„æµ‹æ¨¡å¼å‡†å¤‡æµ‹è¯•æ•°æ®
                if omic_type == "multiomics":
                    # æ£€æŸ¥æ‰€æœ‰ä¸‰ä¸ªç»„å­¦æ•°æ®æ˜¯å¦éƒ½å·²ä¸Šä¼ 
                    required_omics = ["mRNA", "miRNA", "methylation"]
                    missing_omics = [omic for omic in required_omics if omic not in data_arrays]
                    
                    if missing_omics:
                        st.error(f"Missing omic data for multiomics prediction: {', '.join(missing_omics)}")
                    else:
                        # æ£€æŸ¥æ‰€æœ‰ç»„å­¦æ•°æ®æ˜¯å¦æœ‰ç›¸åŒçš„æ ·æœ¬æ•°
                        sample_counts = {omic: data.shape[0] for omic, data in data_arrays.items()}
                        if len(set(sample_counts.values())) > 1:
                            st.error(f"Inconsistent sample counts: {sample_counts}")
                        else:
                            # æ‹¼æ¥å¤šç»„å­¦æ•°æ®
                            test_X = np.concatenate(
                                [data_arrays["mRNA"], data_arrays["miRNA"], data_arrays["methylation"]], 
                                axis=1
                            )
                            
                            st.success(f"Multiomics data prepared: {test_X.shape[0]} samples, {test_X.shape[1]} features")
                else:
                    # å•ç»„å­¦é¢„æµ‹
                    if omic_type not in data_arrays:
                        st.error(f"No {omic_type} data uploaded for {omic_type} prediction.")
                    else:
                        test_X = data_arrays[omic_type]
                        st.success(f"{omic_type} data prepared: {test_X.shape[0]} samples, {test_X.shape[1]} features")
                
                # å¦‚æœæ•°æ®å‡†å¤‡æˆåŠŸï¼Œç»§ç»­åŠ è½½è®­ç»ƒæ•°æ®å’Œè¿›è¡Œé¢„æµ‹
                if 'test_X' in locals():
                    # åŠ è½½è®­ç»ƒæ•°æ®
                    with st.spinner("Loading training data references..."):
                        train_idx, label = load_training_data()
                        if train_idx is None or label is None:
                            st.error("Failed to load training data.")
                        else:
                            # æ ¹æ®ç»„å­¦ç±»å‹å‡†å¤‡è®­ç»ƒæ•°æ®
                            if omic_type == "multiomics":
                                # åŠ è½½å¤šç»„å­¦è®­ç»ƒæ•°æ®
                                try:
                                    omics1 = pd.read_csv("data/tcga_mrna.csv").to_numpy()
                                    omics2 = pd.read_csv("data/tcga_mirna.csv").to_numpy()
                                    omics3 = pd.read_csv("data/tcga_meth.csv").to_numpy()
                                    omics = np.concatenate((omics1, omics2, omics3), axis=1)
                                    train_X = omics[train_idx]
                                except FileNotFoundError:
                                    st.error("Training data files not found. Please ensure the 50-feature training data files are available.")
                                    st.info("Required files: tcga_mrna.csv, tcga_mirna.csv, tcga_meth.csv")
                            elif omic_type == "mRNA":
                                try:
                                    omics1 = pd.read_csv("data/tcga_mrna.csv").to_numpy()
                                    train_X = omics1[train_idx]
                                except FileNotFoundError:
                                    st.error("mRNA training data file not found: tcga_mrna.csv")
                            elif omic_type == "miRNA":
                                try:
                                    omics2 = pd.read_csv("data/tcga_mirna.csv").to_numpy()
                                    train_X = omics2[train_idx]
                                except FileNotFoundError:
                                    st.error("miRNA training data file not found: tcga_mirna.csv")
                            elif omic_type == "methylation":
                                try:
                                    omics3 = pd.read_csv("data/tcga_meth.csv").to_numpy()
                                    train_X = omics3[train_idx]
                                except FileNotFoundError:
                                    st.error("Methylation training data file not found: tcga_meth.csv")
                            
                            if 'train_X' in locals():
                                train_y = label[train_idx]
                                test_y = np.zeros(test_X.shape[0], dtype=int)
                                
                                st.info(f"Training data loaded: {train_X.shape[0]} samples, {train_X.shape[1]} features")
                                
                                # å‡†å¤‡é¢„æµ‹æ•°æ®
                                with st.spinner("Preparing data for prediction..."):
                                    # è½¬æ¢ä¸ºå¼ é‡
                                    data_tr_list = [torch.FloatTensor(train_X)]
                                    data_trte_list = [torch.FloatTensor(np.concatenate((train_X, test_X), axis=0))]
                                    
                                    # å¼ºåˆ¶ä½¿ç”¨CPU
                                    cuda = False
                                    
                                    # å‡†å¤‡ç´¢å¼•
                                    num_tr = data_tr_list[0].shape[0]
                                    num_trte = data_trte_list[0].shape[0]
                                    labels_trte = np.concatenate((train_y, test_y))
                                    trte_idx = {"tr": list(range(num_tr)), "te": list(range(num_tr, num_trte))}
                                    
                                    # å‡†å¤‡æ ‡ç­¾å¼ é‡
                                    labels_tr_tensor = torch.LongTensor(labels_trte[trte_idx["tr"]])
                                    onehot_labels_tr_tensor = one_hot_tensor(labels_tr_tensor, 2)
                                    sample_weight_tr = torch.FloatTensor(
                                        cal_sample_weight(labels_trte[trte_idx["tr"]], 2)
                                    )
                                
                                # åŠ è½½æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹
                                with st.spinner(f"Loading {omic_type} model and making predictions..."):
                                    # è·å–æ¨¡å‹æ–‡ä»¶å¤¹
                                    model_folder = MODEL_MAP[omic_type]
                                    
                                    # è·å–è¾“å…¥ç»´åº¦
                                    dim_list = [x.shape[1] for x in data_tr_list]
                                    
                                    # åˆå§‹åŒ–å¹¶åŠ è½½æ¨¡å‹
                                    trained_model = init_and_load_model(model_folder, dim_list)
                                    if trained_model is None:
                                        st.error(f"Failed to load {omic_type} model from {model_folder}")
                                        st.info("Please ensure the model files are available in the correct directory.")
                                    else:
                                        # è¿›è¡Œé¢„æµ‹
                                        try:
                                            predictions = test_epoch(data_trte_list, trte_idx["te"], trained_model)
                                            y_pred = np.argmax(predictions, axis=1)
                                            
                                            # ä¿å­˜é¢„æµ‹ç»“æœåˆ°session state
                                            st.session_state.risk_prediction_result = {
                                                'predictions': predictions,
                                                'y_pred': y_pred,
                                                'test_X': test_X,
                                                'omic_type': omic_type,
                                                'data_arrays': data_arrays
                                            }
                                            
                                            # æ˜¾ç¤ºä¸Šä¼ çš„æ•°æ®æ‘˜è¦
                                            with st.expander("ğŸ“Š Uploaded Data Summary", expanded=True):
                                                st.markdown(f"**Prediction Mode:** {omic_type}")
                                                st.markdown(f"**Number of Samples:** {test_X.shape[0]}")
                                                st.markdown(f"**Number of Features:** {test_X.shape[1]}")
                                                
                                                if omic_type == "multiomics":
                                                    st.markdown("**Features per Omic Type:** 50 (each)")
                                                    st.markdown("**Total Features:** 150 (50 mRNA + 50 miRNA + 50 methylation)")
                                                else:
                                                    st.markdown(f"**Features:** 50")
                                            
                                            st.subheader("ğŸ¯ Prediction Results")
                                            
                                            # åˆ›å»ºç»“æœè¡¨æ ¼
                                            results = []
                                            for i in range(len(y_pred)):
                                                risk_group = "High Risk" if y_pred[i] == 1 else "Low Risk"
                                                high_risk_prob = predictions[i][1] * 100
                                                low_risk_prob = predictions[i][0] * 100
                                                
                                                # ä¿å­˜ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç»“æœåˆ°session state
                                                if i == 0:
                                                    st.session_state.last_risk_value = 1 if y_pred[i] == 1 else 0
                                                    st.session_state.last_risk_label = risk_group
                                                
                                                # æ·»åŠ é£é™©è§£é‡Š
                                                if y_pred[i] == 1:
                                                    risk_explanation = "Higher likelihood of disease progression"
                                                else:
                                                    risk_explanation = "Lower likelihood of disease progression"
                                                
                                                results.append({
                                                    "Sample": f"Patient {i+1}",
                                                    "Risk Group": risk_group,
                                                    "High Risk Probability": f"{high_risk_prob:.2f}%",
                                                    "Low Risk Probability": f"{low_risk_prob:.2f}%",
                                                    "Interpretation": risk_explanation
                                                })
                                            
                                            results_df = pd.DataFrame(results)
                                            st.dataframe(results_df, use_container_width=True, hide_index=True)
                                            
                                            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                                            high_risk_count = sum(y_pred == 1)
                                            low_risk_count = sum(y_pred == 0)
                                            
                                            col1, col2 = st.columns(2)
                                            with col1:
                                                st.metric("High Risk Patients", f"{high_risk_count} ({high_risk_count/len(y_pred)*100:.1f}%)")
                                            with col2:
                                                st.metric("Low Risk Patients", f"{low_risk_count} ({low_risk_count/len(y_pred)*100:.1f}%)")
                                            
                                            # å¦‚æœé¢„æµ‹äº†é£é™©ç»„åˆ«ï¼Œæ›´æ–°ä¾§è¾¹æ çš„é£é™©ç»„åˆ«é€‰æ‹©
                                            if len(y_pred) > 0:
                                                st.info(f"""
                                                ğŸ’¡ **Suggestion**: The predicted risk group for the first patient is **{st.session_state.last_risk_label}**. 
                                                This value has been automatically selected in the Risk Group dropdown in the sidebar.
                                                You can now use this value for survival prediction.
                                                """)
                                            
                                            # æ·»åŠ ä¸‹è½½æŒ‰é’®
                                            csv = results_df.to_csv(index=False)
                                            st.download_button(
                                                label="ğŸ“¥ Download Prediction Results (CSV)",
                                                data=csv,
                                                file_name=f"lgg_{omic_type}_risk_predictions.csv",
                                                mime="text/csv",
                                            )
                                            
                                            # æ˜¾ç¤ºè¯¦ç»†é¢„æµ‹ä¿¡æ¯
                                            with st.expander("ğŸ” Model and Data Details", expanded=False):
                                                st.markdown(f"""
                                                ### Model Information
                                                - **Model Type**: Feedforward Neural Network (FNN)
                                                - **Prediction Mode**: {omic_type}
                                                - **Model Location**: {MODEL_MAP[omic_type]}
                                                - **Training Samples**: {train_X.shape[0]}
                                                - **Input Features**: {train_X.shape[1]}
                                                
                                                ### Data Dimensions
                                                | Data Type | Samples | Features |
                                                |-----------|---------|----------|
                                                | Training Data | {train_X.shape[0]} | {train_X.shape[1]} |
                                                | Test Data | {test_X.shape[0]} | {test_X.shape[1]} |
                                                
                                                ### Uploaded Files Status
                                                | File Type | Status | Features |
                                                |-----------|--------|----------|
                                                | mRNA | {'âœ… Uploaded' if 'mRNA' in data_arrays else 'âŒ Not uploaded'} | {data_arrays['mRNA'].shape[1] if 'mRNA' in data_arrays else 'N/A'} |
                                                | miRNA | {'âœ… Uploaded' if 'miRNA' in data_arrays else 'âŒ Not uploaded'} | {data_arrays['miRNA'].shape[1] if 'miRNA' in data_arrays else 'N/A'} |
                                                | Methylation | {'âœ… Uploaded' if 'methylation' in data_arrays else 'âŒ Not uploaded'} | {data_arrays['methylation'].shape[1] if 'methylation' in data_arrays else 'N/A'} |
                                                """)
                                            
                                        except Exception as e:
                                            st.error(f"Error during prediction: {str(e)}")
                                            st.info("This may be due to dimension mismatch between the model and data.")

# å¤„ç†ç”Ÿå­˜é¢„æµ‹
if survival_calc_button:
    st.subheader("ğŸ¥ Survival Prediction Results")
    
    # å¦‚æœæœ€è¿‘æœ‰é£é™©ç»„åˆ«é¢„æµ‹ç»“æœï¼Œæ˜¾ç¤ºæç¤º
    if st.session_state.last_risk_label and st.session_state.last_risk_value:
        if st.session_state.last_risk_value != risk_value:
            st.info(f"""
            ğŸ’¡ **Note**: You recently predicted a risk group of **{st.session_state.last_risk_label}** 
            using the Risk Group Prediction tool. The current survival prediction is using the manually selected 
            risk group **{risk_label}**. You may want to update the risk group selection to use the predicted value.
            """)
    
    # æ‰§è¡Œç”Ÿå­˜é¢„æµ‹
    try:
        fig, survival_df, survival_results, cph, data_for_cox = perform_survival_prediction(
            age, grade, risk_value, risk_label
        )
        
        # åœ¨Streamlitä¸­æ˜¾ç¤º
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("ğŸ“‹ Patient Information")
            st.info(f"""
            **Age:** {age} years  
            **Grade:** {grade}  
            **Risk Group:** {risk_label} (value: {risk_value})
            """)
            
            st.subheader("ğŸ“ˆ Survival Rates")
            st.dataframe(
                survival_results,
                use_container_width=True,
                hide_index=True
            )
            
            # æä¾›æ•°æ®ä¸‹è½½
            csv = survival_results.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ Download Survival Data (CSV)",
                data=csv,
                file_name=f"survival_prediction_age{age}_grade{grade}_risk{risk_label}.csv",
                mime="text/csv",
            )
        
        with col2:
            st.subheader("ğŸ“Š Survival Curve")
            st.pyplot(fig)
            
            # æä¾›å›¾è¡¨ä¸‹è½½
            buf = BytesIO()
            fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
            buf.seek(0)
            
            st.download_button(
                label="ğŸ–¼ï¸ Download Chart (PNG)",
                data=buf,
                file_name=f"survival_curve_age{age}_grade{grade}_risk{risk_label}.png",
                mime="image/png",
            )
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        with st.expander("ğŸ“Š Model Information", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Model Summary**")
                st.write(f"- Number of patients in training: {len(data_for_cox)}")
                st.write(f"- Features used: Age, Grade, Risk Group")
                st.write(f"- Model: Cox Proportional Hazards")
                st.write(f"- Concordance Index: {cph.concordance_index_:.3f}")
            
            with col2:
                st.write("**Cox Model Coefficients**")
                coef_df = pd.DataFrame({
                    'Feature': cph.params_.index,
                    'Coefficient': cph.params_.values,
                    'Hazard Ratio': np.exp(cph.params_.values)
                })
                st.dataframe(coef_df, use_container_width=True, hide_index=True)
        
        # æ·»åŠ è§£é‡Šè¯´æ˜
        st.markdown("---")
        st.markdown("""
        ### ğŸ“– Interpretation Guide
        
        1. **Survival Curve**: Shows the probability of survival over time (in months)
        2. **Survival Rate**: Percentage of patients expected to survive at each time point
        3. **95% CI**: 95% confidence interval for the survival estimate
        4. **Grade**: G2 (low grade) vs G3 (high grade) tumors
        5. **Risk Group**: Based on molecular markers (High=1, Low=0)
        
        **Note**: The model is trained on TCGA-LGG data. Predictions are estimates and should be used in conjunction with clinical judgment.
        """)
        
    except Exception as e:
        st.error(f"Error during survival prediction: {str(e)}")
        st.info("Please check if the data files are available and in the correct format.")

# å¦‚æœä¸¤ä¸ªè®¡ç®—éƒ½æ‰§è¡Œäº†ï¼Œæ˜¾ç¤ºåˆ†éš”çº¿
if survival_calc_button and risk_calc_button:
    st.markdown("---")
    st.subheader("ğŸ“Š Combined Results Summary")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Predicted Risk Group", f"{risk_label}")
        st.metric("Patient Age", f"{age} years")
    
    with col2:
        st.metric("Tumor Grade", grade)
        if survival_calc_button and 'survival_results' in locals():
            # è·å–5å¹´ç”Ÿå­˜ç‡
            five_year_survival = None
            for idx, row in survival_results.iterrows():
                if "5 year" in row['Time']:
                    five_year_survival = row['Survival Rate (%)']
                    break
            
            if five_year_survival:
                st.metric("5-Year Survival Rate", five_year_survival)